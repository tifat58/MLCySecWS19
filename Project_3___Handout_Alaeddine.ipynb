{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_3_-_Handout-Hasan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tifat58/MLCySecWS19/blob/master/Project_3___Handout_Alaeddine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4NzyqehHjUlG"
      },
      "source": [
        "# ML in Cybersecurity: Project III\n",
        "\n",
        "## Team\n",
        "  * **Team name**:  *fill this in*\n",
        "  * **Members**:  *fill this in. format: Hasan Md Tusfiqur Alam (s8haalam@stud.uni-saarland.de), name2 (email2), ...*\n",
        "  * **Tutor**: *fill this in*\n",
        "\n",
        "\n",
        "## Logistics\n",
        "  * **Due date**: 12th December 2019, 13:59:59 \n",
        "  * Email the completed notebook to mlcysec_ws1920_staff@lists.cispa.saarland \n",
        "  * Complete this in the previously established **teams of 3**\n",
        "  * Feel free to use the course [mailing list](https://lists.cispa.saarland/listinfo/mlcysec_ws1920_stud) to discuss.\n",
        "  \n",
        "## Timeline\n",
        "  * 28-Nov-2019: Project 3 hand-out\n",
        "  * **12-Dec-2019** (13:59:59): Email completed notebook to mlcysec_ws1920_staff@lists.cispa.saarland\n",
        "\n",
        "  * 19-Dec-2019: Project 3 discussion and summary\n",
        "  \n",
        "  \n",
        "## About this Project\n",
        "In this project, we dive into the vulnerabilities of machine learning models and the difficulties of defending against them. To this end, we require you to implement an evasion attack (craft adversarial examples) yourselves, and defend your own model.   \n",
        "\n",
        "\n",
        "## A Note on Grading\n",
        "The total number of points in this project is 100. We further provide the number of points achievable with each excercise. You should take particular care to document and visualize your results, though.\n",
        "\n",
        "\n",
        " \n",
        "## Filling-in the Notebook\n",
        "You'll be submitting this very notebook that is filled-in with (all!) your code and analysis. Make sure you submit one that has been previously executed in-order. (So that results/graphs are already visible upon opening it). \n",
        "\n",
        "The notebook you submit **should compile** (or should be self-contained and sufficiently commented). Check tutorial 1 on how to set up the Python3 environment.\n",
        "\n",
        "It is extremely important that you **do not** re-order the existing sections. Apart from that, the code blocks that you need to fill-in are given by:\n",
        "```\n",
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "```\n",
        "Feel free to break this into multiple-cells. It's even better if you interleave explanations and code-blocks so that the entire notebook forms a readable \"story\".\n",
        "\n",
        "\n",
        "## Code of Honor\n",
        "We encourage discussing ideas and concepts with other students to help you learn and better understand the course content. However, the work you submit and present **must be original** and demonstrate your effort in solving the presented problems. **We will not tolerate** blatantly using existing solutions (such as from the internet), improper collaboration (e.g., sharing code or experimental data between groups) and plagiarism. If the honor code is not met, no points will be awarded.\n",
        "\n",
        " \n",
        " ## Versions\n",
        "  * v1.0: Initial notebook\n",
        "  * v1.1: Clarifications at 1.1.2, 1.2.2, 2.1\n",
        " \n",
        "  ---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQJ_wKu_FbXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "bc23da64-4dc9-4917-eb5e-a1e7ad3ac197"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ewNwfFvbFaR",
        "colab": {}
      },
      "source": [
        "import time \n",
        " \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import json \n",
        "import time \n",
        "import pickle \n",
        "import sys \n",
        "import csv \n",
        "import os \n",
        "import os.path as osp \n",
        "import shutil \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.display import display, HTML\n",
        " \n",
        "%matplotlib inline \n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots \n",
        "plt.rcParams['image.interpolation'] = 'nearest' \n",
        "plt.rcParams['image.cmap'] = 'gray' \n",
        " \n",
        "# for auto-reloading external modules \n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython \n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "640GrzbOevr0",
        "colab": {}
      },
      "source": [
        "# Some suggestions of our libraries that might be helpful for this project\n",
        "from collections import Counter          # an even easier way to count\n",
        "from multiprocessing import Pool         # for multiprocessing\n",
        "from tqdm import tqdm                    # fancy progress bars\n",
        "\n",
        "# Load other libraries here.\n",
        "# Keep it minimal! We should be easily able to reproduce your code.\n",
        "# We only support sklearn and pytorch.\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "\n",
        "# We preload pytorch as an example\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GJZPEAWYMhYB",
        "colab": {}
      },
      "source": [
        "compute_mode = 'cpu'\n",
        "\n",
        "if compute_mode == 'cpu':\n",
        "    device = torch.device('cpu')\n",
        "elif compute_mode == 'gpu':\n",
        "    # If you are using pytorch on the GPU cluster, you have to manually specify which GPU device to use\n",
        "    # It is extremely important that you *do not* spawn multi-GPU jobs.\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'    # Set device ID here\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    raise ValueError('Unrecognized compute mode')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nxi-lLD0mKHD"
      },
      "source": [
        "#### Helpers\n",
        "\n",
        "In case you choose to have some methods you plan to reuse during the notebook, define them here. This will avoid clutter and keep rest of the notebook succinct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VBbigqdEmKd8",
        "colab": {}
      },
      "source": [
        "def identity_func(foo):\n",
        "    return foo\n",
        "\n",
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n1pcmKkyjT7y"
      },
      "source": [
        "# 1. Attacking an ML-model\n",
        "\n",
        "In this section, we implement an attack ourselves. We then leverage the Foolbox library to craft adversarial examples. First, however, you need a model you can attack. Feel free to choose the DNN/ConvNN from project 1.\n",
        "\n",
        "Hint: you might want to save the trained model to save time later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QaJv_d_Dp7OM"
      },
      "source": [
        "### 1.1.1: Setting up the model (5 Points)\n",
        "\n",
        "Re-use the model from project 1 here and train it until it achieves reasonable accuracy (>92%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c688qdGtO1v-",
        "colab": {}
      },
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "\n",
        "# (1)load data \n",
        "# (2)define model\n",
        "# (3)define loss, optimizer \n",
        "# (4)train\n",
        "# (5)evaluate\n",
        "# print('Epoch %d, Train acc: %f, Test acc: %f' % (epoch, train_acc, test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR3qK428Cig8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "da98decb-c093-47d8-fa5e-230abe1fcd92"
      },
      "source": [
        "batch_size_train = 64 \n",
        "batch_size_test = 1000 \n",
        "n_epochs = 12\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('data/mnist/', train=True, download=True,\n",
        "                              transform=torchvision.transforms.Compose([\n",
        "                                  torchvision.transforms.ToTensor()\n",
        "                              ])), batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('data/mnist/', train=False, download=True,\n",
        "                              transform=torchvision.transforms.Compose([\n",
        "                                  torchvision.transforms.ToTensor(),\n",
        "                              ])), batch_size=batch_size_test, shuffle=True)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9341381.63it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 140997.30it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2324779.75it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 50930.86it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf3uSS0ECihC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self,kernels=5):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 10 output channels, 5x5 square convolution\n",
        "        # kernel \n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=kernels)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=kernels)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0VEkjusCihI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(n_epochs):\n",
        "    net.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = F.log_softmax(net(data))\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset), \n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "            train_counter.append(\n",
        "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "            \n",
        "            torch.save(net.state_dict(), root_dir+'model_3.pth')\n",
        "    train_losses.append(loss.item()) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69fkMROHCihM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    net.eval()\n",
        "    test_loss = 0 \n",
        "    correct = 0 \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = F.log_softmax(net(data))\n",
        "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            \n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_losses.append(test_loss)\n",
        "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), \n",
        "            100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDbJbh0NCihS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab3ffa25-427e-43c8-f144-68a223a3d47e"
      },
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "net = Net()\n",
        "optimizer = optim.SGD(net.parameters(), lr= learning_rate, momentum=momentum)\n",
        "\n",
        "for epoch in range(1, n_epochs):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.338712\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.110489\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.718753\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.500384\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.428305\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.336347\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.229679\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.289542\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.282697\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.208202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.1055, Accuracy: 9676/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.417126\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.187608\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.278032\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.195736\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.207264\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.297065\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.252148\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.596994\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.240377\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.153436\n",
            "\n",
            "Test set: Avg. loss: 0.0775, Accuracy: 9761/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.438237\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.139910\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.260608\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.207981\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.210196\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.074755\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.186385\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.323080\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.586373\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.386108\n",
            "\n",
            "Test set: Avg. loss: 0.0718, Accuracy: 9783/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.094117\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.124015\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.357860\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.153362\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.116706\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.114194\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.044230\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.154964\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.132692\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.221143\n",
            "\n",
            "Test set: Avg. loss: 0.0547, Accuracy: 9829/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.097131\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.189940\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.279239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-31cfd0e3618d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-90f83ceb57ff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4vHkz9KCihZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# net.save_state_dict('best_model.pt')\n",
        "torch.save(net.state_dict(), root_dir+'best_modell.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DEQrdyLHsUIu"
      },
      "source": [
        "### 1.1.2: Implementing an attack (15 Points)\n",
        "\n",
        "We now want you to attack the model trained in the previous step. Please implement the FGSM attack mentioned in the lecture. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gcVZnUNbRKOz",
        "colab": {}
      },
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUOkROW8Cihi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_fgsm( model, device, test_loader, epsilon ):\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        # Send the data and label to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass the data through the model\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # Zero all existing gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0) and (len(adv_examples) < 1000):\n",
        "                adv_ex = perturbed_data\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(),target, adv_ex) )\n",
        "        else:\n",
        "            # Save some adv examples for visualization later\n",
        "            if len(adv_examples) < 1000:\n",
        "                adv_ex = perturbed_data\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), target, adv_ex) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnCO5NjyCihn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3df066b1-3917-4670-c047-6a2ce9456939"
      },
      "source": [
        "model = Net()\n",
        "model.load_state_dict(torch.load(root_dir+'best_model.pt'), strict=False)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVYYg9njCihs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('data/mnist/', train=False, download=True,\n",
        "                              transform=torchvision.transforms.Compose([\n",
        "                                  torchvision.transforms.ToTensor(),\n",
        "                              ])), batch_size=1, shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFbMJRfqCihw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "881a00f9-fc66-4aa5-e354-acffb871b116"
      },
      "source": [
        "\n",
        "epsilons = [0, .05, .1, .15, .2, .25, .3, .4, .5]\n",
        "accuracies = []\n",
        "examples = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    acc, ex = test_fgsm(model, device, test_loader, eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 321 / 10000 = 0.0321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-c1e8fcc5baaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Run test for each epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_fgsm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-70d0b8ee97e4>\u001b[0m in \u001b[0;36mtest_fgsm\u001b[0;34m(model, device, test_loader, epsilon)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Loop over all examples in test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Send the data and label to the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NanOPyvVCih1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "6c414ff9-9904-46d1-8374-95052af42ee0"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons, accuracies, \"*-\")\n",
        "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "plt.xticks(np.arange(0, .35, step=0.05))\n",
        "plt.title(\"Accuracy vs Epsilon\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RNpI3oUoO1wE"
      },
      "source": [
        "### 1.1.3: adversarial sample set (5 Points)\n",
        "\n",
        "Please additionally generate a dataset containing at least 1,000 adversarial examples using FGSM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvYpo9p2O1wF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6146a18e-0149-44b2-8a32-fee8cfad1887"
      },
      "source": [
        "#The generation is implement inside of test_fgsm already !\n",
        "#Here we generate adverserial examples with epsilon=0\n",
        "#The data can be accesses from ex\n",
        "eps=0\n",
        "acc, ex = test_fgsm(model, device, test_loader, eps)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 296 / 10000 = 0.0296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ex3qQp3JolD1"
      },
      "source": [
        "### 1.1.3: Visualizing the results (5 Points)\n",
        "\n",
        "Please chose one sample for each class (for example the first when iterating the test data) and plot the (ten) adversarial examples as well as the predicted label (before and after the attack)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eGkp0B0PO1wJ",
        "colab": {},
        "outputId": "1080fa81-2671-4e39-d1a8-404681afc7ea"
      },
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "cnt = 0\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(len(epsilons)):\n",
        "    for j in range(len(examples[i])):\n",
        "        cnt += 1\n",
        "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "        plt.xticks([], [])\n",
        "        plt.yticks([], [])\n",
        "        if j == 0:\n",
        "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "        orig,adv,ex = examples[i][j]\n",
        "        plt.title(\"{} -> {}\".format(orig, adv))\n",
        "        plt.imshow(ex, cmap=\"gray\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-4cb1e638d169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3-venv/mlcysec/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3-venv/mlcysec/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_ax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3-venv/mlcysec/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msca\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m   1865\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;34m\"\"\"Set the current axes to be a and return a.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbubble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axobservers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3-venv/mlcysec/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mbubble\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbubble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entry_from_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3-venv/mlcysec/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mbubble\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mbubbles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthiso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthiso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthiso\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbubbles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/python3-venv/mlcysec/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \"\"\"\n\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1747 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iPB-GK1CymiV"
      },
      "source": [
        "### 1.2.1: Using libraries for attacks (10 Points)\n",
        "As the field of evasion attacks (in particular for DNN) is very active research field, several libraries have been published that contain attacks. We will work here with the Foolbox (https://github.com/bethgelab/foolbox) library. Please implement two other (recent, advanced) attacks of your choice using this library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pa6rPT53LUW8",
        "colab": {}
      },
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "\n",
        "# (a) attack 1\n",
        "# (b) attack 2\n",
        "\n",
        "!pip install foolbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WL0OPGvCiiH",
        "colab_type": "code",
        "colab": {},
        "outputId": "458c92ca-9f8b-4da4-83f3-cbfb79b7c36b"
      },
      "source": [
        "# (a) attack 1\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('data/mnist/', train=False, download=True,\n",
        "                              transform=torchvision.transforms.Compose([\n",
        "                                  torchvision.transforms.ToTensor(),\n",
        "                              ])), batch_size=1, shuffle=False)\n",
        "import foolbox\n",
        "import torchvision.models as models\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(root_dir+'best_model.pt'),strict=False)\n",
        "print(model)\n",
        "# instantiate model (supports PyTorch, Keras, TensorFlow (Graph and Eager), JAX, MXNet and many more)\n",
        "fmodel = foolbox.models.PyTorchModel(model, bounds= (0,1), num_classes=10)\n",
        "\n",
        "# get a batch of images and labels and print the accuracy\n",
        "# -> 0.9375\n",
        "\n",
        "images = np.expand_dims(images, axis=1)\n",
        "\n",
        "attack = foolbox.attacks.GradientSignAttack(fmodel)\n",
        "i = 0\n",
        "adversarials_GSA = []\n",
        "for index, (data, target) in enumerate(test_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data, target = data.data.numpy(), target.data.numpy()\n",
        "    adversarials_GSA.append(attack(data, target).squeeze())\n",
        "    if index >= 9:\n",
        "        break\n",
        "    i = i + 1\n",
        "\n",
        "print(len(adversarials_GSA))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/mak/python3-venv/mlcysec/lib/python3.7/site-packages/foolbox/models/pytorch.py:71: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
            "  \"The PyTorch model is in training mode and therefore might\"\n",
            "/Users/mak/python3-venv/mlcysec/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DcZPSD9CiiN",
        "colab_type": "code",
        "colab": {},
        "outputId": "532cecc0-721e-42b6-a9fc-8b7c4ec3a2c3"
      },
      "source": [
        "import foolbox\n",
        "import torchvision.models as models\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(root_dir+'best_model.pt'),strict=False)\n",
        "print(model)\n",
        "# instantiate model (supports PyTorch, Keras, TensorFlow (Graph and Eager), JAX, MXNet and many more)\n",
        "fmodel = foolbox.models.PyTorchModel(model, bounds= (0,1), num_classes=10)\n",
        "\n",
        "# get a batch of images and labels and print the accuracy\n",
        "images, labels = foolbox.utils.samples(dataset= 'mnist', batchsize=10, data_format='channels_first', bounds=(0, 1))\n",
        "#print(np.mean(fmodel.forward(images).argmax(axis=-1) == labels))\n",
        "# -> 0.9375\n",
        "\n",
        "attack = foolbox.attacks.CarliniWagnerL2Attack(fmodel, distance=foolbox.distances.Linf)\n",
        "\n",
        "\n",
        "i = 0\n",
        "adversarials_CWA = []\n",
        "for index, (data, target) in enumerate(test_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data, target = data.data.numpy(), target.data.numpy()\n",
        "    adversarials_CWA.append(attack(data, target).squeeze())\n",
        "    if index >= 9:\n",
        "        break\n",
        "print(len(adversarials_CWA))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/mak/python3-venv/mlcysec/lib/python3.7/site-packages/foolbox/models/pytorch.py:71: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
            "  \"The PyTorch model is in training mode and therefore might\"\n",
            "/Users/mak/python3-venv/mlcysec/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o6_slpDCiiQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "08bee843-16a9-49b2-b763-014bf5384b33"
      },
      "source": [
        "# Original image\n",
        "original_images = []\n",
        "original_class = []\n",
        "for index, (data, target)  in enumerate(test_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data, target = data.data.numpy(), target.data.numpy()\n",
        "    data, target = data.squeeze(), target\n",
        "    original_images.append(data)\n",
        "    original_class.append(target)\n",
        "    if index >= 9:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "print(len(original_images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xVH821TOymic"
      },
      "source": [
        "### 1.2.2: Visualizing the results (20 Points)\n",
        "As before, please plot the new adversarial examples. Compare all crafting techniques (FGSM, 2 methods from Foolbox).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "69nc8PMRymid",
        "colab": {},
        "outputId": "d5a3f2b4-ed87-492f-9995-f2be3eea08f0"
      },
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "\n",
        "# template code (Please feel free to change this)\n",
        "# (each column corresponds to one attack method)\n",
        "col_titles = ['Ori','FGSM','GSA', 'CWA'] \n",
        "nsamples = 10\n",
        "nrows = nsamples\n",
        "ncols = len(col_titles)\n",
        "\n",
        "fig, axes = plt.subplots(nrows,ncols,figsize=(8,12))  # create the figure with subplots\n",
        "[ax.set_axis_off() for ax in axes.ravel()]  # remove the axis\n",
        "\n",
        "for ax, col in zip(axes[0], col_titles): # set up the title for each column\n",
        "    ax.set_title(col,fontdict={'fontsize':18,'color':'b'})\n",
        "\n",
        "for i in range(nsamples):\n",
        "    axes[i,0].imshow(original_images[i])\n",
        "    #axes[i,1].imshow(adv_FGSM[i])\n",
        "    axes[i,2].imshow(adversarials_GSA[i])\n",
        "    axes[i,3].imshow(adversarials_CWA[i])\n",
        "                  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x864 with 40 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m6HxYLl3O1wV"
      },
      "source": [
        "Which differences do you observe when comparing different attack methods? Why?   \n",
        "Please write a brief summary of your findings.   \n",
        "* Does the attack always succeed (the model make wrong prediction on the adversarial sample)?\n",
        "* How different is the adversarial sample from the original image?\n",
        "(L0,L2,Linf norm)  \n",
        "* How about the computation cost of each attack method?\n",
        "* Does the attack require white-box access to the model?\n",
        "* ....."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KJUmrv5Bymij"
      },
      "source": [
        "# 2. Defending an ML model\n",
        "\n",
        "So far, we have focused on attacking an ML model. In this section, we want you to defend your model. As before concerning the attack, you can chose an example from the lecture, or experiment with any idea you have.\n",
        "\n",
        "We do not require the defense to work perfectly - but what we want you to understand is why it works or why it does not work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0gHUFK6Mymik"
      },
      "source": [
        "### 2.1: Implementing a defense of your choice (25 Points)\n",
        "As stated before, feel free to implement a defense or mitigation of your choice. Evaluate the defense on adversarial examples. This entails at least the 1,000 examples crafted from FGSM.   \n",
        "Also, you are encouraged (optional) to defend against the two other attack methods, i.e. you are free to increase this special test set (for example by >30 examples (>10 from your FGSM attack, >10 from both the two other attacks of the library))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DD0UalSeymim",
        "colab": {}
      },
      "source": [
        "teacher_model= Net()\n",
        "teacher_model.load_state_dict(torch.load(root_dir+'best_modell.pt'), strict=False)\n",
        "\n",
        "student_model=Net()\n",
        "def train_distillation( n_epochs):\n",
        "    \n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        pred = teacher_model(data)\n",
        "        optimizer.zero_grad()\n",
        "        output = student_model(data)\n",
        "        loss = F.kl_div(F.log_softmax(output, dim=-1), F.softmax(pred, dim=-1), reduction='batchmean')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset), \n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "            train_counter.append(\n",
        "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "            \n",
        "            torch.save(student_model.state_dict(), root_dir+'model_des.pth')\n",
        "    train_losses.append(loss.item()) \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RzA4twpFJ5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_distillation():\n",
        "    student_model.eval()\n",
        "    test_loss = 0 \n",
        "    correct = 0 \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = F.log_softmax(student_model(data))\n",
        "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            \n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_losses.append(test_loss)\n",
        "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), \n",
        "            100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X423PSVAGgyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "210a85fd-682f-4e47-a9fb-e18e04c66f40"
      },
      "source": [
        "\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n",
        "optimizer = optim.SGD(student_model.parameters(), lr= learning_rate, momentum=momentum)\n",
        "\n",
        "for epoch in range(1, n_epochs):\n",
        "    train_distillation(epoch)\n",
        "    test_distillation()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.028781\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.140195\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.088034\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.992600\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.606040\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.013826\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.982217\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.840193\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.966888\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.709972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.4012, Accuracy: 9008/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.454725\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.361738\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.239621\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.240460\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.209557\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.284628\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.241076\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.275183\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.315840\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.153197\n",
            "\n",
            "Test set: Avg. loss: 0.1945, Accuracy: 9527/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.250171\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.246922\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.257266\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.182992\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.192654\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.102197\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.161886\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.291681\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.179960\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.229303\n",
            "\n",
            "Test set: Avg. loss: 0.1665, Accuracy: 9656/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.184011\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.212930\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.279301\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.145174\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.186078\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.291439\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.176789\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.219554\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.268056\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.154934\n",
            "\n",
            "Test set: Avg. loss: 0.1614, Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.184597\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.252359\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.151872\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.267440\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.157814\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.217014\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.157967\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.171273\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.124976\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.198050\n",
            "\n",
            "Test set: Avg. loss: 0.1484, Accuracy: 9730/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.114365\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.194392\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.195494\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.267163\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.167765\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.257303\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.191573\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.111598\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.322345\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.299862\n",
            "\n",
            "Test set: Avg. loss: 0.1416, Accuracy: 9730/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.167854\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.129532\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.216693\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.177902\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.162724\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.242397\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.117394\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.165162\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.164268\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.122496\n",
            "\n",
            "Test set: Avg. loss: 0.1313, Accuracy: 9743/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.202094\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.139744\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.260618\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.171675\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.121082\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.190230\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.188352\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.147596\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.282431\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.195479\n",
            "\n",
            "Test set: Avg. loss: 0.1412, Accuracy: 9743/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.330468\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.181533\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.186725\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.158080\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.192838\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.248909\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.265351\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.310028\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.191644\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.294805\n",
            "\n",
            "Test set: Avg. loss: 0.1359, Accuracy: 9761/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.183978\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.213475\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.123992\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.200863\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.113426\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.134639\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.162906\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.137439\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.178100\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.155179\n",
            "\n",
            "Test set: Avg. loss: 0.1390, Accuracy: 9777/10000 (98%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.204557\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.240133\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.146800\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.208624\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.138287\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.206536\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.197853\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.095945\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.257460\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.202447\n",
            "\n",
            "Test set: Avg. loss: 0.1296, Accuracy: 9783/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaYyY3q0T5cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We save the student trained model\n",
        "torch.save(student_model.state_dict(), root_dir+'best_student.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN0WH1jKVev1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_distillation_adv():\n",
        "    student_model.eval()\n",
        "    test_loss = 0 \n",
        "    correct = 0 \n",
        "    with torch.no_grad():\n",
        "        for data in ex:\n",
        "            output = F.log_softmax(student_model(data[2]))\n",
        "            test_loss += F.nll_loss(output, data[0], size_average=False).item()\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            \n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_losses.append(test_loss)\n",
        "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), \n",
        "            100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCU1WZZnYE66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "0806fd46-52e5-46b2-a8d8-618b8df678e9"
      },
      "source": [
        "\n",
        "epsilons = [0, .05, .1, .15, .2, .25, .3, .4, .5]\n",
        "accuracies_adv = []\n",
        "examples_adv = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    acc, ex = test_fgsm(student_model, device, test_loader, eps)\n",
        "    accuracies_adv.append(acc)\n",
        "    examples_adv.append(ex)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 9783 / 10000 = 0.9783\n",
            "Epsilon: 0.05\tTest Accuracy = 9474 / 10000 = 0.9474\n",
            "Epsilon: 0.1\tTest Accuracy = 8758 / 10000 = 0.8758\n",
            "Epsilon: 0.15\tTest Accuracy = 7159 / 10000 = 0.7159\n",
            "Epsilon: 0.2\tTest Accuracy = 4668 / 10000 = 0.4668\n",
            "Epsilon: 0.25\tTest Accuracy = 2040 / 10000 = 0.204\n",
            "Epsilon: 0.3\tTest Accuracy = 729 / 10000 = 0.0729\n",
            "Epsilon: 0.4\tTest Accuracy = 47 / 10000 = 0.0047\n",
            "Epsilon: 0.5\tTest Accuracy = 4 / 10000 = 0.0004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn8bk3N6FKIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data in ex:\n",
        "  torch.from_numpy(img).float().to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9l3AVsjyiMDO",
        "colab": {}
      },
      "source": [
        "def evaluate_fgsm( model, device, epsilon ):\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data in ex:\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data[3].grad.data\n",
        "\n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data[3], epsilon, data_grad)\n",
        "\n",
        "        # classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == data[2].item():\n",
        "            correct += 1\n",
        "            \n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(ex))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(ex), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW6qy5bmi-nw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "bcd63deb-a53a-47ed-c340-346556ad97d3"
      },
      "source": [
        "acc_FGSM=evaluate_fgsm( model, device, epsilon )\n",
        "acc_FGSM_defend=evaluate_fgsm( student_model, device, epsilon )\n",
        "print('Accuracy on adversarial samples (FGSM) %.2f'%acc_FGSM)\n",
        "print('Accuracy on adversarial samples (FGSM) after defense %.2f'%acc_FGSM_defend)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-f6c329666222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc_FGSM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_fgsm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macc_FGSM_defend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_fgsm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy on adversarial samples (FGSM) %.2f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0macc_FGSM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy on adversarial samples (FGSM) after defense %.2f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0macc_FGSM_defend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-a1872e899942>\u001b[0m in \u001b[0;36mevaluate_fgsm\u001b[0;34m(model, device, epsilon)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Collect datagrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdata_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Call FGSM Attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sIMRqecuymir"
      },
      "source": [
        "### 2.2: Conclusions (15 Points)\n",
        "Please interpret the results of your defense here. \n",
        "\n",
        "* What did you try to make the classifier more robust against FGSM? \n",
        "* Why did it work? \n",
        "* Is the classifier now robust against FGSM?  \n",
        "* ...\n",
        "\n",
        "Feel free to state any interesting finding you encountered during this project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "scROCZjDymit",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}